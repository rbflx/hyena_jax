{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 23:00:42.294269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "# https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html#generating-random-numbers\n",
    "jax.config.update('jax_threefry_partitionable', True)\n",
    "\n",
    "from jax import random, numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "from jax.sharding import Mesh, PartitionSpec\n",
    "from jax.experimental import mesh_utils\n",
    "\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from helpers import ShardedTrainer, MeshManager, get_batch_gen\n",
    "\n",
    "from hyena import HyenaOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1698094846.926878 1350637 pjrt_api.cc:98] GetPjrtApi was found for tpu at /home/amir/.venv311/lib/python3.11/site-packages/libtpu/libtpu.so\n",
      "I0000 00:00:1698094846.926959 1350637 pjrt_api.cc:67] PJRT_Api is set for device type tpu\n",
      "I0000 00:00:1698094846.926964 1350637 pjrt_api.cc:72] PJRT plugin for tpu has PJRT API version 0.30. The framework PJRT API version is 0.30.\n",
      "I0000 00:00:1698094849.939847 1350637 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003403878\n",
      "475.82037\n"
     ]
    }
   ],
   "source": [
    "# causality check\n",
    "\n",
    "layer = HyenaOperator(\n",
    "    max_len=256,\n",
    "    d_model=128,\n",
    "    pos_embed_dim=7,\n",
    "    filter_features=64,\n",
    "    num_filter_layers=4\n",
    ")\n",
    "\n",
    "key, init_key, drop_key, data_key = random.split(key, 4)\n",
    "\n",
    "x = random.normal(data_key, (1, 256, 128))\n",
    "\n",
    "params = layer.init({\"params\": init_key, \"dropout\": drop_key}, x)\n",
    "\n",
    "@jax.grad\n",
    "def out_grads(x):\n",
    "    logits = layer.apply(params, x, rngs={\"dropout\": drop_key}, train=True)\n",
    "    # Get some scalar-valued output with respect to which to evaluate grad.\n",
    "    out = jnp.sum(logits[:, 10, :])\n",
    "    return out\n",
    "\n",
    "\n",
    "grads = out_grads(x)\n",
    "# Expectation: grad wrt sequence items with pos > 10 should be negligible, with pos <= 10 significant.\n",
    "print(jnp.sum(jnp.abs(grads[0,11:,:])))\n",
    "print(jnp.sum(jnp.abs(grads[0,:11,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 µs ± 1.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# performance test\n",
    "\n",
    "jit_apply = jax.jit(lambda x: layer.apply(params, x, rngs={\"dropout\": drop_key}, train=True))\n",
    "\n",
    "# warmup\n",
    "jit_apply(x)\n",
    "\n",
    "%timeit jit_apply(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard transformer decoder\n",
    "\n",
    "class HyenaDecoderLayer(nn.Module):\n",
    "    features: int\n",
    "    max_len: int\n",
    "    filter_features: int\n",
    "    num_filter_layers: int\n",
    "    pos_embed_dim: int\n",
    "    order: int\n",
    "    hidden_features: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train: bool = True):\n",
    "        residual = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = HyenaOperator(\n",
    "            self.max_len,\n",
    "            self.features,\n",
    "            self.pos_embed_dim,\n",
    "            self.filter_features,\n",
    "            self.num_filter_layers,\n",
    "            self.order,\n",
    "            dropout=self.dropout,\n",
    "        )(x, train=train)\n",
    "        x = nn.Dropout(rate=self.dropout)(x, deterministic=not train)\n",
    "        x = residual + x\n",
    "\n",
    "        residual = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = nn.Dense(self.hidden_features)(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dense(self.features)(x)\n",
    "        x = nn.Dropout(rate=self.dropout)(x, deterministic=not train)\n",
    "        x = residual + x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class HyenaDecoder(nn.Module):\n",
    "    embedding: nn.Module\n",
    "    layer_func: Callable\n",
    "    n_layers: int\n",
    "    dropout: float = 0.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, tokens, train: bool = True):\n",
    "        embeds = self.embedding(tokens)\n",
    "        embeds = nn.Dropout(rate=self.dropout)(embeds, deterministic=not train)\n",
    "\n",
    "        for _ in range(self.n_layers):\n",
    "            embeds = self.layer_func(dropout=self.dropout)(embeds, train=train)\n",
    "        \n",
    "        embeds = nn.LayerNorm()(embeds)\n",
    "        logits = self.embedding.attend(embeds)\n",
    "        return logits * 1 / jnp.sqrt(self.embedding.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 128\n",
    "n_layers = 6\n",
    "seq_len = 512\n",
    "embed_dim = 7\n",
    "filter_features = 64\n",
    "num_filters_layers = 4\n",
    "order = 2\n",
    "dropout = 0.1\n",
    "\n",
    "embed_fn = partial(nn.Embed, num_embeddings=65, features=n_dim)\n",
    "layer = partial(\n",
    "    HyenaDecoderLayer,\n",
    "    features=n_dim,\n",
    "    max_len=seq_len,\n",
    "    filter_features=filter_features,\n",
    "    num_filter_layers=num_filters_layers,\n",
    "    pos_embed_dim=embed_dim,\n",
    "    order=order,\n",
    "    hidden_features=n_dim * 4,\n",
    ")\n",
    "model = HyenaDecoder(\n",
    "    embedding=embed_fn(),\n",
    "    layer_func=layer,\n",
    "    n_layers=n_layers,\n",
    "    dropout=dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareTrainer(ShardedTrainer):\n",
    "    def get_loss_function(self):\n",
    "        def calculate_loss(params, rng, batch, train):\n",
    "            inp_data, labels = batch\n",
    "\n",
    "            rng, dropout_apply_rng = random.split(rng)\n",
    "            logits = self.model.apply({'params': params}, inp_data, train=train, rngs={'dropout': dropout_apply_rng})\n",
    "            loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "            acc = (logits.argmax(axis=-1) == labels).mean()\n",
    "            return loss, (acc, rng)\n",
    "        return calculate_loss\n",
    "    \n",
    "    def init_model(self, exmp_batch):\n",
    "        self.rng = jax.random.PRNGKey(self.seed)\n",
    "        self.rng, init_rng, dropout_init_rng = jax.random.split(self.rng, 3)\n",
    "\n",
    "        # learning rate schedule and optimizer\n",
    "        sched = optax.warmup_cosine_decay_schedule(\n",
    "            init_value=0,\n",
    "            peak_value=1e-3,\n",
    "            warmup_steps=100,\n",
    "            decay_steps=self.max_iters,\n",
    "            end_value=7e-4,\n",
    "        )\n",
    "        optimizer = optax.chain(optax.clip_by_global_norm(1.0),\n",
    "                                optax.adamw(sched, weight_decay=0.1, b2=0.98))\n",
    "\n",
    "        # initialization function\n",
    "        def init_fn(init_rng, dropout_init_rng, x, model, optimizer):\n",
    "            inp_data = x[0]\n",
    "            variables = self.model.init({'params': init_rng, 'dropout': dropout_init_rng}, inp_data, train=True)\n",
    "            params = variables['params']\n",
    "            state = train_state.TrainState.create(\n",
    "                apply_fn=model.apply,\n",
    "                params=params,\n",
    "                tx=optimizer\n",
    "            )\n",
    "            return state\n",
    "\n",
    "        # get init_fn output sharding (state)\n",
    "        abstract_vars, logical_state_spec = MeshManager.get_var_sharding(init_fn,\n",
    "                                                                         init_rng,\n",
    "                                                                         dropout_init_rng,\n",
    "                                                                         exmp_batch,\n",
    "                                                                         model=self.model,\n",
    "                                                                         optimizer=optimizer)\n",
    "        # convert logical to physical sharding according to rules\n",
    "        rules = (('batch', 'data'),)\n",
    "        state_sharding = self.mesh_manager.logical_to_mesh(logical_state_spec, rules)\n",
    "\n",
    "        jitted_init = jax.jit(\n",
    "            init_fn, static_argnums=(3,4),\n",
    "            in_shardings=(None, None, self.data_sharding),\n",
    "            out_shardings=state_sharding\n",
    "        )\n",
    "        \n",
    "        initialized_state = jitted_init(init_rng, dropout_init_rng, exmp_batch, model, optimizer)\n",
    "\n",
    "        return initialized_state, state_sharding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh(device_ids=array([[0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [6],\n",
      "       [7],\n",
      "       [4],\n",
      "       [5]]), axis_names=('data', 'model'))\n"
     ]
    }
   ],
   "source": [
    "device_count = jax.device_count()\n",
    "\n",
    "device_mesh = mesh_utils.create_device_mesh((8,1))\n",
    "mesh = Mesh(devices=device_mesh, axis_names=('data', 'model'))\n",
    "mesh_manager = MeshManager(mesh)\n",
    "print(mesh)\n",
    "\n",
    "data_shard_spec = PartitionSpec('data', None)\n",
    "data_sharding = mesh_manager.mesh_sharding(data_shard_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "# Test on the tiny Shakespeare dataset.\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = request.urlopen(url)\n",
    "text = response.read().decode(\"utf-8\")\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "char2token = {c: i for (i, c) in enumerate(vocab)}\n",
    "token2char = {i: c for (i, c) in enumerate(vocab)}\n",
    "tokens = jnp.array([char2token[c] for c in text])\n",
    "\n",
    "split_idx = int(0.9*len(tokens))\n",
    "train, test = tokens[:split_idx], tokens[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                     TPU 0                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">                                     TPU 1                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">                                     TPU 2                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                                     TPU 3                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                                                                                </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">                                     TPU 6                                      </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">                                     TPU 7                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">                                     TPU 4                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">                                                                                </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">                                     TPU 5                                      </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;214;97;107m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107mTPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;214;97;107m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;140;162;82m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82mTPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;140;162;82m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;222;158;214m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mTPU 3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;222;158;214m                                                                                \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;231;203;148m                                     \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148mTPU 6\u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m                                      \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;231;203;148m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;107;110;207m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207mTPU 7\u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;107;110;207m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;165;81;148m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148mTPU 4\u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;165;81;148m                                                                                \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;140;109;49m                                     \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49mTPU 5\u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m                                      \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;140;109;49m                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(idxs, data, seq_len):\n",
    "    tok_idxs = jnp.array(idxs)[:, jnp.newaxis] + jnp.arange(seq_len)\n",
    "    input_tokens = data[tok_idxs]\n",
    "    target_tokens = data[tok_idxs + 1]\n",
    "\n",
    "    batch = (input_tokens, target_tokens)\n",
    "    sharded_batch = mesh_manager.shard_data(batch, data_sharding)\n",
    "\n",
    "    return sharded_batch\n",
    "\n",
    "get_train_batch = partial(get_batch, data=train, seq_len=seq_len)\n",
    "get_test_batch = partial(get_batch, data=test, seq_len=seq_len)\n",
    "\n",
    "exmp_batch = get_batch(np.arange(0, device_count), train, seq_len)\n",
    "jax.debug.visualize_array_sharding(exmp_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "# Don't choose inputs from the last seq_len indices as targets would exceed train/test size.\n",
    "train_size = train.shape[0]-(seq_len+1)\n",
    "test_size = test.shape[0]-(seq_len+1)\n",
    "\n",
    "# Don't iterate over every single item in an epoch (unnecessarily large overlap between batches).\n",
    "train_steps_per_epoch = train_size//(batch_size*256)\n",
    "test_steps_per_epoch = test_size//(batch_size*25)\n",
    "\n",
    "get_train_gen = partial(get_batch_gen,\n",
    "                        train_size,\n",
    "                        get_train_batch,\n",
    "                        batch_size,\n",
    "                        shuffle=True,\n",
    "                        steps_per_epoch=train_steps_per_epoch)\n",
    "get_val_gen = partial(get_batch_gen,\n",
    "                        test_size,\n",
    "                        get_test_batch,\n",
    "                        batch_size,\n",
    "                        shuffle=True,\n",
    "                        steps_per_epoch=test_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir/work/tests/hyena_own/helpers.py:81: UserWarning: WARNING: Checkpoint directory already exists for this model. Model will not be saved.\n",
      "  warnings.warn('WARNING: Checkpoint directory already exists for this model. Model will not be saved.')\n"
     ]
    }
   ],
   "source": [
    "key, train_key = random.split(key)\n",
    "\n",
    "num_train_iters = train_steps_per_epoch * n_epochs\n",
    "\n",
    "# Create a trainer module with specified hyperparameters\n",
    "trainer = ShakespeareTrainer(model,\n",
    "                    model_name='ShakespeareHyena',\n",
    "                    exmp_batch=exmp_batch,\n",
    "                    max_iters=num_train_iters,\n",
    "                    data_sharding=data_sharding,\n",
    "                    mesh_manager=mesh_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3458e245fabf4d2ab004b0bd7694f1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f57b450395040e2b0f187d1e5fe74a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 4.0149312019348145, accuracy: 0.11218111962080002\n",
      "Epoch 1, val loss: 3.791551113128662, accuracy: 0.17125403881072998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845cc52c867e4b25af3b8eef78531421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss: 3.501777410507202, accuracy: 0.25221025943756104\n",
      "Epoch 2, val loss: 3.1810083389282227, accuracy: 0.3415014147758484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26894181a0ad40b3b8387cc1e7b911ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 2.9595961570739746, accuracy: 0.35975173115730286\n",
      "Epoch 3, val loss: 2.726419687271118, accuracy: 0.3989589512348175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1435dffcc3d944629554ba213158363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss: 2.5661888122558594, accuracy: 0.41193678975105286\n",
      "Epoch 4, val loss: 2.3917236328125, accuracy: 0.4314327538013458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f6b3fd766240e1a0021c03e04b5788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss: 2.274303436279297, accuracy: 0.4431597590446472\n",
      "Epoch 5, val loss: 2.157914638519287, accuracy: 0.4516880214214325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c9aa3a49a8421584a31166bd44e1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss: 2.0633928775787354, accuracy: 0.4688175320625305\n",
      "Epoch 6, val loss: 1.9853150844573975, accuracy: 0.47214099764823914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d039a0a49dbc4dab9164a30dadb3f409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss: 1.899193286895752, accuracy: 0.49304500222206116\n",
      "Epoch 7, val loss: 1.860067367553711, accuracy: 0.488347589969635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12cf0acdab84d469a473954e32bdeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss: 1.779293179512024, accuracy: 0.5109378099441528\n",
      "Epoch 8, val loss: 1.7787940502166748, accuracy: 0.49998098611831665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b4f5a888c427385470bdb2c3dae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss: 1.6863524913787842, accuracy: 0.5263186693191528\n",
      "Epoch 9, val loss: 1.7086975574493408, accuracy: 0.5103892683982849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413d089f965a468a826c70ce96eb73ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 1.6162011623382568, accuracy: 0.536638081073761\n",
      "Epoch 10, val loss: 1.6681420803070068, accuracy: 0.5164732933044434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6951fff97a554f45853e1908d5617105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss: 1.5634039640426636, accuracy: 0.5451920032501221\n",
      "Epoch 11, val loss: 1.634684443473816, accuracy: 0.5254865884780884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f84c94de98a41929e3738ae2130b8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss: 1.5197592973709106, accuracy: 0.5531581044197083\n",
      "Epoch 12, val loss: 1.5946767330169678, accuracy: 0.5327993035316467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5baedd2dad4c7797b5ad420f850c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss: 1.483270287513733, accuracy: 0.5598369836807251\n",
      "Epoch 13, val loss: 1.5763037204742432, accuracy: 0.5365680456161499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2490a2bfed5842b094262db59f072a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss: 1.4509625434875488, accuracy: 0.5663596987724304\n",
      "Epoch 14, val loss: 1.559666633605957, accuracy: 0.5423752069473267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5beb3f3ead046b5bea100b879707e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss: 1.4306414127349854, accuracy: 0.5696631073951721\n",
      "Epoch 15, val loss: 1.5368115901947021, accuracy: 0.5470408797264099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea88581244404c499abe439f51bb5169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss: 1.4068697690963745, accuracy: 0.5741622447967529\n",
      "Epoch 16, val loss: 1.5246070623397827, accuracy: 0.5481204986572266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78c7677664d4d8fa6a5307e3ef0cbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss: 1.3909343481063843, accuracy: 0.5775141716003418\n",
      "Epoch 17, val loss: 1.5133845806121826, accuracy: 0.5499081611633301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fc187114ea4958a884e471c76d8e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss: 1.375877022743225, accuracy: 0.5809716582298279\n",
      "Epoch 18, val loss: 1.505707859992981, accuracy: 0.5519471168518066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ef31d4582a4796bb163d7efc8357f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss: 1.3627945184707642, accuracy: 0.583055853843689\n",
      "Epoch 19, val loss: 1.4985592365264893, accuracy: 0.5551549792289734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdcd40eec244fbda185db1e3bfc5f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss: 1.3479368686676025, accuracy: 0.5862631797790527\n",
      "Epoch 20, val loss: 1.4887877702713013, accuracy: 0.5582107305526733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2049e8e48185482797f94a7b33baddd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss: 1.3416390419006348, accuracy: 0.5872867703437805\n",
      "Epoch 21, val loss: 1.4888650178909302, accuracy: 0.5587790608406067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3cc1acea174726bee4408ebaa4102e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss: 1.3287646770477295, accuracy: 0.5910634398460388\n",
      "Epoch 22, val loss: 1.4821523427963257, accuracy: 0.560383677482605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6ba9f7c7554044b89ad811833a4657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss: 1.3183168172836304, accuracy: 0.5931326150894165\n",
      "Epoch 23, val loss: 1.473443865776062, accuracy: 0.5614863038063049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb0cb06dea045629e2a165d61a37915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss: 1.313948392868042, accuracy: 0.5935578942298889\n",
      "Epoch 24, val loss: 1.4609413146972656, accuracy: 0.564784824848175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a184ceb3df44f090449dfe159918cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train loss: 1.3001668453216553, accuracy: 0.5972680449485779\n",
      "Epoch 25, val loss: 1.45468008518219, accuracy: 0.5652434825897217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd776f532dc41a1a9261677f769b807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train loss: 1.2967040538787842, accuracy: 0.5980319380760193\n",
      "Epoch 26, val loss: 1.4609057903289795, accuracy: 0.566074550151825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7aa3400d314b9d967a794f02f69f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train loss: 1.2916759252548218, accuracy: 0.5988369584083557\n",
      "Epoch 27, val loss: 1.453465461730957, accuracy: 0.5678883194923401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a49153703d45ab99b13562da0b4758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train loss: 1.2828031778335571, accuracy: 0.6011037230491638\n",
      "Epoch 28, val loss: 1.4495930671691895, accuracy: 0.569448709487915\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86926d2564b4deea5d4776ac60e5ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train loss: 1.2764837741851807, accuracy: 0.6032164692878723\n",
      "Epoch 29, val loss: 1.4473909139633179, accuracy: 0.568307638168335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f47230c64ab4583af4381c6a1308da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train loss: 1.2716366052627563, accuracy: 0.6041309833526611\n",
      "Epoch 30, val loss: 1.4437079429626465, accuracy: 0.570770263671875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0311f1c8cc94db885ce9f4e3cc946ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, train loss: 1.267196774482727, accuracy: 0.6054187417030334\n",
      "Epoch 31, val loss: 1.432915449142456, accuracy: 0.5716667771339417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f80c80f4e4d4d7799ac01e83b839732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train loss: 1.2644811868667603, accuracy: 0.6058909893035889\n",
      "Epoch 32, val loss: 1.4323363304138184, accuracy: 0.57298743724823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fde9647a5df485fbf6195dff6a41239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, train loss: 1.2542824745178223, accuracy: 0.6082468628883362\n",
      "Epoch 33, val loss: 1.4410500526428223, accuracy: 0.5711709856987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c9fd3e833d459a81a376722f86e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, train loss: 1.2522103786468506, accuracy: 0.608751118183136\n",
      "Epoch 34, val loss: 1.4313586950302124, accuracy: 0.5740825533866882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f383d8a44044bb955fa77c494bff6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, train loss: 1.24908447265625, accuracy: 0.6094680428504944\n",
      "Epoch 35, val loss: 1.4331425428390503, accuracy: 0.574985682964325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0c037a19084dfca8c962930753a063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, train loss: 1.244664192199707, accuracy: 0.6108153462409973\n",
      "Epoch 36, val loss: 1.4388471841812134, accuracy: 0.5726384520530701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaf36ab73204e89ae675b48cee1c2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, train loss: 1.2403591871261597, accuracy: 0.6117779016494751\n",
      "Epoch 37, val loss: 1.431612491607666, accuracy: 0.57403165102005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b00388dbd423e96a4d7f28316d79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, train loss: 1.2349002361297607, accuracy: 0.6131226420402527\n",
      "Epoch 38, val loss: 1.4228782653808594, accuracy: 0.5760365128517151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fbbf23888f4327bf6c6a395d5c8b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, train loss: 1.2320034503936768, accuracy: 0.6140176653862\n",
      "Epoch 39, val loss: 1.43060302734375, accuracy: 0.5749737024307251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0555820f95024609b29cfa75357eaa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, train loss: 1.2268190383911133, accuracy: 0.6152999401092529\n",
      "Epoch 40, val loss: 1.4329246282577515, accuracy: 0.5764301419258118\n"
     ]
    }
   ],
   "source": [
    "with mesh:\n",
    "    trainer.train_model(get_train_gen, get_val_gen, num_epochs=n_epochs)\n",
    "\n",
    "val_gen, train_key = get_val_gen(key=train_key)\n",
    "val_acc, val_loss = trainer.eval_model(val_gen)\n",
    "\n",
    "# Bind parameters to model for easier inference\n",
    "trainer.model_bd = trainer.model.bind({'params': trainer.state.params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jax.jit\n",
    "def pred(inp, key):\n",
    "    logits = trainer.model_bd(inp, train=False)\n",
    "    # Sample instead of simply taking argmax to reduce repetition.\n",
    "    token_idx = random.categorical(key, logits, axis=-1)\n",
    "    return token_idx\n",
    "\n",
    "# warmup\n",
    "pred(jnp.zeros((1, seq_len), dtype=jnp.int32), key).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Alas, my father, and I know come; let's prejoice\n",
      "To die for reply, and they there, like man\n",
      "Where will abuse off: mine arst Abury,'\n",
      "I dead to. This true that was all eyes,\n",
      "Passing him till 'we must speak of monsta's maid,\n",
      "Should not enbear him! hear the duke, whood they are\n",
      "commend to thee to do it?\n",
      "And send not Barnardine, but giving a scorn\n",
      "To find a perfect.\n",
      "\n",
      "MENENIUS:\n",
      "Tell him, you have sead'd to stand up to death.\n",
      "You shall not indeed, say 'stain.\n",
      "Long that was won; I'll not such a man!\n",
      "shut it not that beheld how all I like thee,\n",
      "Ratcliff, tribunes no dear silence we hereafter.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Most ragely from him succession:\n",
      "I pretty troopque, Richmond the gates to say,\n",
      "By curity of the matters but herein;\n",
      "Which with a few day in the hire infect.\n",
      "Look your silence than my name in k\n"
     ]
    }
   ],
   "source": [
    "cond_text = \"ROMEO:\"\n",
    "cond_tokens = [char2token[c] for c in cond_text]\n",
    "cur_in = jnp.array([cond_tokens])\n",
    "cur_idx = cur_in.shape[-1]\n",
    "cur_in = np.pad(cur_in, ((0,0),(0,seq_len-cur_idx)))\n",
    "\n",
    "sample_key = random.PRNGKey(3)\n",
    "\n",
    "# number of chars to generate\n",
    "num_gen = 800\n",
    "\n",
    "for i in range(0, num_gen):\n",
    "    sample_key = random.fold_in(sample_key, i)\n",
    "\n",
    "    pred_tokens = pred(cur_in, sample_key)\n",
    "    cur_pred_token = pred_tokens[0,cur_idx-1]\n",
    "\n",
    "    if cur_idx < seq_len:\n",
    "        cur_in[0,cur_idx] = cur_pred_token\n",
    "        cur_idx += 1\n",
    "    else:\n",
    "        cur_in = np.roll(cur_in, shift=-1, axis=-1)\n",
    "        cur_in[0,cur_idx-1] = cur_pred_token\n",
    "    \n",
    "    cond_tokens.append(int(cur_pred_token))\n",
    "\n",
    "print(''.join([token2char[c] for c in cond_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
